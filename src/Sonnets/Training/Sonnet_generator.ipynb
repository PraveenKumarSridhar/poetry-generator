{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Sonnet_generator.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-EWyvS3qUjc"
      },
      "source": [
        "## Can we write a Sonnet like its the middle ages?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4nPKXnoqUjd"
      },
      "source": [
        "![sonnet](https://github.com/PraveenKumarSridhar/poetry-generator/blob/develop/src/Sonnets/Training/Sonnet_art.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLZ53StPqj2B"
      },
      "source": [
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ourZVE1yqUje"
      },
      "source": [
        "### 1.0 Loading the data\n",
        "<hr/>\n",
        "Let's start with loading the actual data and seeing a small sample of it, say the first 300 characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_146r3bjqUje",
        "outputId": "c2e06153-f644-49a9-ccee-e96c1f87a091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "data = open('/content/sonnets.txt').read()\n",
        "data[0:300]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"FROM fairest creatures we desire increase,\\nThat thereby beauty's rose might never die,\\nBut as the riper should by time decease,\\nHis tender heir might bear his memory:\\nBut thou, contracted to thine own bright eyes,\\nFeed'st thy light'st flame with self-substantial fuel,\\nMaking a famine where abundance\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7-O_D8TqUji"
      },
      "source": [
        "### 2.0 Load the packages\n",
        "<hr/>\n",
        "Remeber to check the requirements file for packages used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q3n_ZSvqUjj"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers \n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uawVxMMSqUjl"
      },
      "source": [
        "Checking the tensorflow version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HGCSz3IOqUjm",
        "outputId": "afdd9301-9fe5-4f14-d623-f90806e3b4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzTCJqrMqUjo"
      },
      "source": [
        "### 3.0 Tokenizing the training data\n",
        "<hr/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "KZj8_ZcwqUjp",
        "outputId": "68115f43-6837-4e23-8be1-8405202feaab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print('Total number of words in corpus:',total_words)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of words in corpus: 3211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgXd0QLAqUjs"
      },
      "source": [
        "### 4.0 Preparing the data for training\n",
        "<hr/>\n",
        "This is the most important part of this entire script and can be broadly split into 5 steps. So let's get into it shall we,\n",
        "\n",
        "For each line in the txt file (training data):\n",
        " #### 4.1) Converting text to sequences.\n",
        "\n",
        "   You can do that using the following:\n",
        "\n",
        "    tokenizer.texts_to_sequences([line])\n",
        "    \n",
        "   Once you convert the text to sequence the output of it would look some thing like the following:\n",
        "\n",
        "    [34, 417, 877, 166, 213, 517]\n",
        " \n",
        " #### 4.2) Creating the N_gram sequences.\n",
        "   Now to create N-gram sequences that would look like \n",
        "\n",
        "    [34,417]\n",
        "    [34,417,877] \n",
        "    [34,417,877,166]\n",
        "    [34,417,877,166,213]\n",
        "    [34,417,877,166,213,517]\n",
        "\n",
        " #### 4.3) Finding the max sequence length and the padding the rest.\n",
        "  \n",
        "   The first thing to do here is to find the larges sequence length. After that, you are going to do pre padding using:\n",
        "\n",
        "    pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "   Once you are done it would look something like this:\n",
        "\n",
        "    [0,0,0,0,34,417]\n",
        "    [0,0,0,34,417,877] \n",
        "    [0,0,34,417,877,166]\n",
        "    [0,34,417,877,166,213]\n",
        "    [34,417,877,166,213,517]\n",
        "\n",
        " #### 4.4) Creating the predictors and the labels.\n",
        "\n",
        "   This is where the most interesting part comes in, we are going to consider the last element in the N_gram sequence arrays we got above as labes and the rest of the array as the predictors:\n",
        "    \n",
        "    PREDICTORS                      LABLES\n",
        "    [0,0,0,0,34]                     417\n",
        "    [0,0,0,34,417]                   877\n",
        "    [0,0,34,417,877]                 166\n",
        "    [0,34,417,877,166]               213\n",
        "    [34,417,877,166,213]             517\n",
        "\n",
        "The code for all of the above steps are concatenated together in the next code block:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Bic7YKtbqUjs"
      },
      "source": [
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2tkadeJqUjv"
      },
      "source": [
        "#### 5.0 Defining the model\n",
        "<hr/>\n",
        "This is where we are going to define the models architechure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juhW5hyoqg0s",
        "outputId": "4f4d872a-2ea1-4ace-c0e6-0a46e7a91e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# Defining the model.\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(total_words,100,input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150,return_sequences=True)))\n",
        "model.add(Dropout(0.18))\n",
        "model.add(Bidirectional(LSTM(128)))\n",
        "model.add(Dense(total_words/2,activation='relu',kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_19 (Embedding)     (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "bidirectional_39 (Bidirectio (None, 10, 300)           301200    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 10, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_40 (Bidirectio (None, 256)               439296    \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 1605)              412485    \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 6,630,947\n",
            "Trainable params: 6,630,947\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2-J_JWyy75H"
      },
      "source": [
        "#### 6.0 Training the model\n",
        "<hr/>\n",
        "Now to actually start training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyzrotGNrbPW",
        "outputId": "f94bcc36-a8c6-4991-dc72-2e394db9ecb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " history = model.fit(predictors, label, epochs=150, verbose=1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15462 samples\n",
            "Epoch 1/150\n",
            "15462/15462 [==============================] - 11s 700us/sample - loss: 6.9980 - accuracy: 0.0204\n",
            "Epoch 2/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 6.5198 - accuracy: 0.0206\n",
            "Epoch 3/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 6.4149 - accuracy: 0.0261\n",
            "Epoch 4/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 6.2887 - accuracy: 0.0333\n",
            "Epoch 5/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 6.1671 - accuracy: 0.0389\n",
            "Epoch 6/150\n",
            "15462/15462 [==============================] - 7s 445us/sample - loss: 6.0440 - accuracy: 0.0414\n",
            "Epoch 7/150\n",
            "15462/15462 [==============================] - 7s 456us/sample - loss: 5.9224 - accuracy: 0.0451\n",
            "Epoch 8/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 5.8080 - accuracy: 0.0499\n",
            "Epoch 9/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 5.6818 - accuracy: 0.0579\n",
            "Epoch 10/150\n",
            "15462/15462 [==============================] - 7s 443us/sample - loss: 5.5633 - accuracy: 0.0636\n",
            "Epoch 11/150\n",
            "15462/15462 [==============================] - 7s 436us/sample - loss: 5.4377 - accuracy: 0.0747\n",
            "Epoch 12/150\n",
            "15462/15462 [==============================] - 7s 443us/sample - loss: 5.3140 - accuracy: 0.0785\n",
            "Epoch 13/150\n",
            "15462/15462 [==============================] - 7s 456us/sample - loss: 5.1874 - accuracy: 0.0934\n",
            "Epoch 14/150\n",
            "15462/15462 [==============================] - 7s 473us/sample - loss: 5.0611 - accuracy: 0.1002\n",
            "Epoch 15/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 4.9373 - accuracy: 0.1075\n",
            "Epoch 16/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 4.8189 - accuracy: 0.1171\n",
            "Epoch 17/150\n",
            "15462/15462 [==============================] - 7s 435us/sample - loss: 4.6934 - accuracy: 0.1306\n",
            "Epoch 18/150\n",
            "15462/15462 [==============================] - 7s 435us/sample - loss: 4.5689 - accuracy: 0.1415\n",
            "Epoch 19/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 4.4365 - accuracy: 0.1530\n",
            "Epoch 20/150\n",
            "15462/15462 [==============================] - 7s 437us/sample - loss: 4.3229 - accuracy: 0.1682\n",
            "Epoch 21/150\n",
            "15462/15462 [==============================] - 7s 434us/sample - loss: 4.1892 - accuracy: 0.1802\n",
            "Epoch 22/150\n",
            "15462/15462 [==============================] - 7s 436us/sample - loss: 4.0746 - accuracy: 0.1919\n",
            "Epoch 23/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 3.9494 - accuracy: 0.2112\n",
            "Epoch 24/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 3.8304 - accuracy: 0.2293\n",
            "Epoch 25/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 3.7042 - accuracy: 0.2481\n",
            "Epoch 26/150\n",
            "15462/15462 [==============================] - 7s 437us/sample - loss: 3.5928 - accuracy: 0.2747\n",
            "Epoch 27/150\n",
            "15462/15462 [==============================] - 7s 440us/sample - loss: 3.4800 - accuracy: 0.3005\n",
            "Epoch 28/150\n",
            "15462/15462 [==============================] - 7s 437us/sample - loss: 3.3625 - accuracy: 0.3212\n",
            "Epoch 29/150\n",
            "15462/15462 [==============================] - 7s 435us/sample - loss: 3.2596 - accuracy: 0.3458\n",
            "Epoch 30/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 3.1584 - accuracy: 0.3727\n",
            "Epoch 31/150\n",
            "15462/15462 [==============================] - 7s 435us/sample - loss: 3.0500 - accuracy: 0.3928\n",
            "Epoch 32/150\n",
            "15462/15462 [==============================] - 7s 435us/sample - loss: 2.9651 - accuracy: 0.4117\n",
            "Epoch 33/150\n",
            "15462/15462 [==============================] - 7s 432us/sample - loss: 2.8652 - accuracy: 0.4382\n",
            "Epoch 34/150\n",
            "15462/15462 [==============================] - 7s 437us/sample - loss: 2.7730 - accuracy: 0.4571\n",
            "Epoch 35/150\n",
            "15462/15462 [==============================] - 7s 434us/sample - loss: 2.6826 - accuracy: 0.4788\n",
            "Epoch 36/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 2.5935 - accuracy: 0.5004\n",
            "Epoch 37/150\n",
            "15462/15462 [==============================] - 7s 443us/sample - loss: 2.5361 - accuracy: 0.5135\n",
            "Epoch 38/150\n",
            "15462/15462 [==============================] - 7s 437us/sample - loss: 2.4598 - accuracy: 0.5270\n",
            "Epoch 39/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 2.3693 - accuracy: 0.5531\n",
            "Epoch 40/150\n",
            "15462/15462 [==============================] - 7s 442us/sample - loss: 2.3004 - accuracy: 0.5698\n",
            "Epoch 41/150\n",
            "15462/15462 [==============================] - 7s 441us/sample - loss: 2.2394 - accuracy: 0.5852\n",
            "Epoch 42/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 2.1782 - accuracy: 0.6022\n",
            "Epoch 43/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 2.1149 - accuracy: 0.6174\n",
            "Epoch 44/150\n",
            "15462/15462 [==============================] - 7s 435us/sample - loss: 2.0597 - accuracy: 0.6264\n",
            "Epoch 45/150\n",
            "15462/15462 [==============================] - 7s 440us/sample - loss: 2.0019 - accuracy: 0.6411\n",
            "Epoch 46/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 1.9481 - accuracy: 0.6509\n",
            "Epoch 47/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 1.8973 - accuracy: 0.6651\n",
            "Epoch 48/150\n",
            "15462/15462 [==============================] - 7s 441us/sample - loss: 1.8530 - accuracy: 0.6768\n",
            "Epoch 49/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 1.8033 - accuracy: 0.6868\n",
            "Epoch 50/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 1.7477 - accuracy: 0.7031\n",
            "Epoch 51/150\n",
            "15462/15462 [==============================] - 7s 437us/sample - loss: 1.7146 - accuracy: 0.7050\n",
            "Epoch 52/150\n",
            "15462/15462 [==============================] - 7s 436us/sample - loss: 1.6888 - accuracy: 0.7114\n",
            "Epoch 53/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 1.6376 - accuracy: 0.7222\n",
            "Epoch 54/150\n",
            "15462/15462 [==============================] - 7s 440us/sample - loss: 1.5971 - accuracy: 0.7304\n",
            "Epoch 55/150\n",
            "15462/15462 [==============================] - 7s 440us/sample - loss: 1.5749 - accuracy: 0.7365\n",
            "Epoch 56/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 1.5400 - accuracy: 0.7419\n",
            "Epoch 57/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 1.5034 - accuracy: 0.7505\n",
            "Epoch 58/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 1.4738 - accuracy: 0.7551\n",
            "Epoch 59/150\n",
            "15462/15462 [==============================] - 7s 466us/sample - loss: 1.4595 - accuracy: 0.7562\n",
            "Epoch 60/150\n",
            "15462/15462 [==============================] - 7s 472us/sample - loss: 1.4153 - accuracy: 0.7682\n",
            "Epoch 61/150\n",
            "15462/15462 [==============================] - 7s 440us/sample - loss: 1.4013 - accuracy: 0.7690\n",
            "Epoch 62/150\n",
            "15462/15462 [==============================] - 7s 441us/sample - loss: 1.3810 - accuracy: 0.7762\n",
            "Epoch 63/150\n",
            "15462/15462 [==============================] - 7s 442us/sample - loss: 1.3430 - accuracy: 0.7795\n",
            "Epoch 64/150\n",
            "15462/15462 [==============================] - 7s 440us/sample - loss: 1.3193 - accuracy: 0.7825\n",
            "Epoch 65/150\n",
            "15462/15462 [==============================] - 7s 439us/sample - loss: 1.3156 - accuracy: 0.7842\n",
            "Epoch 66/150\n",
            "15462/15462 [==============================] - 7s 438us/sample - loss: 1.2973 - accuracy: 0.7866\n",
            "Epoch 67/150\n",
            "15462/15462 [==============================] - 7s 445us/sample - loss: 1.2771 - accuracy: 0.7879\n",
            "Epoch 68/150\n",
            "15462/15462 [==============================] - 7s 441us/sample - loss: 1.2380 - accuracy: 0.7955\n",
            "Epoch 69/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 1.2483 - accuracy: 0.7930\n",
            "Epoch 70/150\n",
            "15462/15462 [==============================] - 7s 440us/sample - loss: 1.2239 - accuracy: 0.7969\n",
            "Epoch 71/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 1.2139 - accuracy: 0.7965\n",
            "Epoch 72/150\n",
            "15462/15462 [==============================] - 7s 452us/sample - loss: 1.1881 - accuracy: 0.8023\n",
            "Epoch 73/150\n",
            "15462/15462 [==============================] - 7s 446us/sample - loss: 1.1788 - accuracy: 0.8038\n",
            "Epoch 74/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 1.1611 - accuracy: 0.8046\n",
            "Epoch 75/150\n",
            "15462/15462 [==============================] - 7s 441us/sample - loss: 1.1535 - accuracy: 0.8080\n",
            "Epoch 76/150\n",
            "15462/15462 [==============================] - 7s 445us/sample - loss: 1.1449 - accuracy: 0.8073\n",
            "Epoch 77/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 1.1240 - accuracy: 0.8104\n",
            "Epoch 78/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 1.1201 - accuracy: 0.8114\n",
            "Epoch 79/150\n",
            "15462/15462 [==============================] - 7s 443us/sample - loss: 1.1173 - accuracy: 0.8114\n",
            "Epoch 80/150\n",
            "15462/15462 [==============================] - 7s 445us/sample - loss: 1.0836 - accuracy: 0.8174\n",
            "Epoch 81/150\n",
            "15462/15462 [==============================] - 7s 442us/sample - loss: 1.0865 - accuracy: 0.8145\n",
            "Epoch 82/150\n",
            "15462/15462 [==============================] - 7s 443us/sample - loss: 1.0711 - accuracy: 0.8187\n",
            "Epoch 83/150\n",
            "15462/15462 [==============================] - 7s 445us/sample - loss: 1.0667 - accuracy: 0.8172\n",
            "Epoch 84/150\n",
            "15462/15462 [==============================] - 7s 458us/sample - loss: 1.0573 - accuracy: 0.8189\n",
            "Epoch 85/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 1.0404 - accuracy: 0.8225\n",
            "Epoch 86/150\n",
            "15462/15462 [==============================] - 7s 445us/sample - loss: 1.0360 - accuracy: 0.8238\n",
            "Epoch 87/150\n",
            "15462/15462 [==============================] - 7s 443us/sample - loss: 1.0395 - accuracy: 0.8193\n",
            "Epoch 88/150\n",
            "15462/15462 [==============================] - 7s 441us/sample - loss: 1.0399 - accuracy: 0.8196\n",
            "Epoch 89/150\n",
            "15462/15462 [==============================] - 7s 442us/sample - loss: 1.0174 - accuracy: 0.8232\n",
            "Epoch 90/150\n",
            "15462/15462 [==============================] - 7s 443us/sample - loss: 1.0060 - accuracy: 0.8242\n",
            "Epoch 91/150\n",
            "15462/15462 [==============================] - 7s 443us/sample - loss: 0.9956 - accuracy: 0.8280\n",
            "Epoch 92/150\n",
            "15462/15462 [==============================] - 7s 443us/sample - loss: 1.0072 - accuracy: 0.8224\n",
            "Epoch 93/150\n",
            "15462/15462 [==============================] - 7s 448us/sample - loss: 1.0002 - accuracy: 0.8261\n",
            "Epoch 94/150\n",
            "15462/15462 [==============================] - 7s 446us/sample - loss: 0.9863 - accuracy: 0.8247\n",
            "Epoch 95/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 0.9788 - accuracy: 0.8256\n",
            "Epoch 96/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 0.9787 - accuracy: 0.8263\n",
            "Epoch 97/150\n",
            "15462/15462 [==============================] - 7s 445us/sample - loss: 0.9752 - accuracy: 0.8269\n",
            "Epoch 98/150\n",
            "15462/15462 [==============================] - 7s 445us/sample - loss: 0.9598 - accuracy: 0.8312\n",
            "Epoch 99/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 0.9547 - accuracy: 0.8320\n",
            "Epoch 100/150\n",
            "15462/15462 [==============================] - 7s 445us/sample - loss: 0.9390 - accuracy: 0.8311\n",
            "Epoch 101/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 0.9601 - accuracy: 0.8279\n",
            "Epoch 102/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 0.9481 - accuracy: 0.8294\n",
            "Epoch 103/150\n",
            "15462/15462 [==============================] - 7s 446us/sample - loss: 0.9439 - accuracy: 0.8269\n",
            "Epoch 104/150\n",
            "15462/15462 [==============================] - 7s 461us/sample - loss: 0.9396 - accuracy: 0.8287\n",
            "Epoch 105/150\n",
            "15462/15462 [==============================] - 7s 471us/sample - loss: 0.9418 - accuracy: 0.8289\n",
            "Epoch 106/150\n",
            "15462/15462 [==============================] - 7s 451us/sample - loss: 0.9159 - accuracy: 0.8331\n",
            "Epoch 107/150\n",
            "15462/15462 [==============================] - 7s 449us/sample - loss: 0.9241 - accuracy: 0.8324\n",
            "Epoch 108/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 0.9169 - accuracy: 0.8319\n",
            "Epoch 109/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 0.9048 - accuracy: 0.8338\n",
            "Epoch 110/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 0.9112 - accuracy: 0.8309\n",
            "Epoch 111/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 0.8995 - accuracy: 0.8355\n",
            "Epoch 112/150\n",
            "15462/15462 [==============================] - 7s 449us/sample - loss: 0.8827 - accuracy: 0.8367\n",
            "Epoch 113/150\n",
            "15462/15462 [==============================] - 7s 448us/sample - loss: 0.8905 - accuracy: 0.8341\n",
            "Epoch 114/150\n",
            "15462/15462 [==============================] - 7s 448us/sample - loss: 0.9188 - accuracy: 0.8269\n",
            "Epoch 115/150\n",
            "15462/15462 [==============================] - 7s 452us/sample - loss: 0.8951 - accuracy: 0.8347\n",
            "Epoch 116/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 0.8936 - accuracy: 0.8348\n",
            "Epoch 117/150\n",
            "15462/15462 [==============================] - 7s 448us/sample - loss: 0.8921 - accuracy: 0.8345\n",
            "Epoch 118/150\n",
            "15462/15462 [==============================] - 7s 453us/sample - loss: 0.9151 - accuracy: 0.8282\n",
            "Epoch 119/150\n",
            "15462/15462 [==============================] - 7s 452us/sample - loss: 0.8739 - accuracy: 0.8371\n",
            "Epoch 120/150\n",
            "15462/15462 [==============================] - 7s 450us/sample - loss: 0.8549 - accuracy: 0.8413\n",
            "Epoch 121/150\n",
            "15462/15462 [==============================] - 7s 451us/sample - loss: 0.8661 - accuracy: 0.8375\n",
            "Epoch 122/150\n",
            "15462/15462 [==============================] - 7s 448us/sample - loss: 0.8710 - accuracy: 0.8340\n",
            "Epoch 123/150\n",
            "15462/15462 [==============================] - 7s 454us/sample - loss: 0.8630 - accuracy: 0.8373\n",
            "Epoch 124/150\n",
            "15462/15462 [==============================] - 7s 450us/sample - loss: 0.8657 - accuracy: 0.8353\n",
            "Epoch 125/150\n",
            "15462/15462 [==============================] - 7s 448us/sample - loss: 0.8672 - accuracy: 0.8350\n",
            "Epoch 126/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 0.8690 - accuracy: 0.8330\n",
            "Epoch 127/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 0.8811 - accuracy: 0.8335\n",
            "Epoch 128/150\n",
            "15462/15462 [==============================] - 7s 470us/sample - loss: 0.8477 - accuracy: 0.8379\n",
            "Epoch 129/150\n",
            "15462/15462 [==============================] - 7s 453us/sample - loss: 0.8473 - accuracy: 0.8351\n",
            "Epoch 130/150\n",
            "15462/15462 [==============================] - 7s 455us/sample - loss: 0.8461 - accuracy: 0.8360\n",
            "Epoch 131/150\n",
            "15462/15462 [==============================] - 7s 449us/sample - loss: 0.8340 - accuracy: 0.8413\n",
            "Epoch 132/150\n",
            "15462/15462 [==============================] - 7s 450us/sample - loss: 0.8373 - accuracy: 0.8397\n",
            "Epoch 133/150\n",
            "15462/15462 [==============================] - 7s 449us/sample - loss: 0.8398 - accuracy: 0.8371\n",
            "Epoch 134/150\n",
            "15462/15462 [==============================] - 7s 452us/sample - loss: 0.8370 - accuracy: 0.8368\n",
            "Epoch 135/150\n",
            "15462/15462 [==============================] - 7s 446us/sample - loss: 0.8264 - accuracy: 0.8426\n",
            "Epoch 136/150\n",
            "15462/15462 [==============================] - 7s 451us/sample - loss: 0.8322 - accuracy: 0.8392\n",
            "Epoch 137/150\n",
            "15462/15462 [==============================] - 7s 450us/sample - loss: 0.8390 - accuracy: 0.8356\n",
            "Epoch 138/150\n",
            "15462/15462 [==============================] - 7s 448us/sample - loss: 0.8559 - accuracy: 0.8324\n",
            "Epoch 139/150\n",
            "15462/15462 [==============================] - 7s 450us/sample - loss: 0.8382 - accuracy: 0.8377\n",
            "Epoch 140/150\n",
            "15462/15462 [==============================] - 7s 446us/sample - loss: 0.8234 - accuracy: 0.8386\n",
            "Epoch 141/150\n",
            "15462/15462 [==============================] - 7s 455us/sample - loss: 0.8308 - accuracy: 0.8367\n",
            "Epoch 142/150\n",
            "15462/15462 [==============================] - 7s 452us/sample - loss: 0.8150 - accuracy: 0.8401\n",
            "Epoch 143/150\n",
            "15462/15462 [==============================] - 7s 446us/sample - loss: 0.8072 - accuracy: 0.8401\n",
            "Epoch 144/150\n",
            "15462/15462 [==============================] - 7s 444us/sample - loss: 0.8267 - accuracy: 0.8364\n",
            "Epoch 145/150\n",
            "15462/15462 [==============================] - 7s 450us/sample - loss: 0.8255 - accuracy: 0.8355\n",
            "Epoch 146/150\n",
            "15462/15462 [==============================] - 7s 449us/sample - loss: 0.8414 - accuracy: 0.8346\n",
            "Epoch 147/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 0.8129 - accuracy: 0.8386\n",
            "Epoch 148/150\n",
            "15462/15462 [==============================] - 7s 447us/sample - loss: 0.8033 - accuracy: 0.8404\n",
            "Epoch 149/150\n",
            "15462/15462 [==============================] - 7s 475us/sample - loss: 0.8150 - accuracy: 0.8393\n",
            "Epoch 150/150\n",
            "15462/15462 [==============================] - 7s 465us/sample - loss: 0.8138 - accuracy: 0.8393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9ofmb_EyckC"
      },
      "source": [
        "#### 7.0 Ploting the performance of the model.\n",
        "<hr/>\n",
        "\n",
        "Here we are going to plot 2 graphs ***accuracy vs epochs*** and ***loss vs epochs*** ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwJNFGlMresc",
        "outputId": "b495b447-b0db-42d8-bd62-7487440dfc10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "plt.savefig('/content/accuracy_plot.png')\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "plt.savefig('/content/loss_plot.png')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1d3H8c+PhE0W2YICAQKIuLAEjajQSnAriEt9rE+xWLf6oJWK4gJVqmKrdal9qj4qVevSVuuCu6hYtwpqqwYEFAEXFg2iLCqLghD4PX+ciURMyCTM5N6ZfN+v17yYmXtn5seFfOfk3HPPMXdHRETiq0HUBYiIyPYpqEVEYk5BLSIScwpqEZGYU1CLiMScglpEJOYU1BJ7ZvaMmZ2c6n1rWEOxmZWm+n1FkpEbdQGSncxsXYWHOwHfAJsTj89w93uTfS93H5aOfUUyhYJa0sLdm5ffN7PFwOnu/vy2+5lZrruX1WVtIplGXR9Sp8q7EMxsvJl9CtxlZq3NbIqZrTCzLxL38yu85l9mdnri/ilm9oqZXZfYd5GZDavlvt3MbJqZrTWz583sZjO7J8m/x56Jz/rSzOaa2dEVth1hZu8m3nepmV2QeL5d4u/2pZl9bmbTzUw/g1It/SeRKOwKtAG6AqMI/w/vSjzuAqwHbtrO6/cHFgDtgGuBO8zMarHvP4A3gLbARODnyRRvZg2BJ4F/Au2Bs4F7zaxXYpc7CN07LYDewIuJ588HSoE8YBfgYkBzOEi1FNQShS3AZe7+jbuvd/dV7v6wu3/t7muBK4HB23n9Ene/3d03A38FOhCCL+l9zawLsB9wqbtvdPdXgCeSrP8AoDlwdeK1LwJTgBMS2zcBe5lZS3f/wt1nVni+A9DV3Te5+3TXZDuSBAW1RGGFu28of2BmO5nZrWa2xMzWANOAVmaWU8XrPy2/4+5fJ+42r+G+HYHPKzwH8HGS9XcEPnb3LRWeWwJ0Stw/DjgCWGJmL5vZgYnn/wB8APzTzBaa2a+T/Dyp5xTUEoVtW5HnA72A/d29JXBQ4vmqujNSYRnQxsx2qvBc5yRf+wnQeZv+5S7AUgB3f9PdjyF0izwGPJh4fq27n+/u3YGjgfPM7JAd/HtIPaCgljhoQeiX/tLM2gCXpfsD3X0JUAJMNLNGiVbvUUm+/HXga2CcmTU0s+LEa+9PvNdIM9vZ3TcBawhdPZjZkWa2W6KPfDVhuOKWyj9CZCsFtcTB9UBTYCXwH2BqHX3uSOBAYBVwBfAAYbz3drn7RkIwDyPUfAtwkrvPT+zyc2BxohvnzMTnAPQEngfWAf8GbnH3l1L2t5GsZTqXIRKY2QPAfHdPe4tepCbUopZ6y8z2M7MeZtbAzIYCxxD6lEViRVcmSn22K/AIYRx1KfBLd38r2pJEvk9dHyIiMaeuDxGRmEtL10e7du28oKAgHW8tIpKVZsyYsdLd8yrblpagLigooKSkJB1vLSKSlcxsSVXb1PUhIhJzCmoRkZhTUIuIxJzGUYvUA5s2baK0tJQNGzZUv7OkVZMmTcjPz6dhw4ZJv0ZBLVIPlJaW0qJFCwoKCqh6jQVJN3dn1apVlJaW0q1bt6RfV23Xh5n1MrNZFW5rzOzcHapWROrUhg0baNu2rUI6YmZG27Zta/ybTbUtandfABQmPiSHMOfuo7UpUkSio5COh9r8O9T0ZOIhwIeJuXxTavNm+P3v4Z//TPU7i4hktpoG9Qjgvso2mNkoMysxs5IVK1bUuJCcHPjDH+Dxx2v8UhGJuVWrVlFYWEhhYSG77rornTp1+vbxxo0bt/vakpISxowZU+1nDBw4MCW1/utf/+LII49MyXulStInE82sEWH5oIsq2+7utwG3ARQVFdVqpqfu3eHDD2vzShGJs7Zt2zJr1iwAJk6cSPPmzbngggu+3V5WVkZubuVxVFRURFFRUbWf8dprr6Wm2BiqSYt6GDDT3T9LVzE9esDChel6dxGJk1NOOYUzzzyT/fffn3HjxvHGG29w4IEH0r9/fwYOHMiCBQuA77ZwJ06cyGmnnUZxcTHdu3fnxhtv/Pb9mjdv/u3+xcXF/OQnP2GPPfZg5MiRlM8S+vTTT7PHHnuw7777MmbMmBq1nO+77z769OlD7969GT9+PACbN2/mlFNOoXfv3vTp04c//elPANx4443stdde9O3blxEjRuzwsarJ8LwTqKLbI1W6d4fHHgv91TlVrT8tIjvk3HMh0bhNmcJCuP76mr+utLSU1157jZycHNasWcP06dPJzc3l+eef5+KLL+bhhx/+3mvmz5/PSy+9xNq1a+nVqxe//OUvvzcm+a233mLu3Ll07NiRQYMG8eqrr1JUVMQZZ5zBtGnT6NatGyeccELSdX7yySeMHz+eGTNm0Lp1aw4//HAee+wxOnfuzNKlS3nnnXcA+PLLLwG4+uqrWbRoEY0bN/72uR2RVIvazJoBhxEmWU+b7t1h0yZYujSdnyIicXH88ceTk2iVrV69muOPP57evXszduxY5s6dW+lrhg8fTuPGjWnXrh3t27fns8++/0v+gAEDyM/Pp0GDBhQWFrJ48WLmz59P9+7dvx2/XJOgfvPNNykuLiYvL4/c3FxGjhzJtGnT6N69OwsXLuTss89m6tSptGzZEoC+ffsycuRI7rnnniq7dGoiqXdw968Iq2CkVY8e4c8PP4QuXdL9aSL1U21avunSrFmzb+9fcsklDBkyhEcffZTFixdTXFxc6WsaN2787f2cnBzKyspqtU8qtG7dmtmzZ/Pss8/y5z//mQcffJA777yTp556imnTpvHkk09y5ZVX8vbbb+9QYMdqro/u3cOf6qcWqX9Wr15Np06dALj77rtT/v69evVi4cKFLF68GIAHHngg6dcOGDCAl19+mZUrV7J582buu+8+Bg8ezMqVK9myZQvHHXccV1xxBTNnzmTLli18/PHHDBkyhGuuuYbVq1ezbt26Hao9VpeQd+4MubkKapH6aNy4cZx88slcccUVDB8+POXv37RpU2655RaGDh1Ks2bN2G+//arc94UXXiA/P//bx5MnT+bqq69myJAhuDvDhw/nmGOOYfbs2Zx66qls2bIFgKuuuorNmzdz4oknsnr1atydMWPG0KpVqx2qPS1rJhYVFXltFw7YbTfYbz+4L62nLUXql3nz5rHnnntGXUbk1q1bR/PmzXF3Ro8eTc+ePRk7dmyd11HZv4eZzXD3SschxqrrAzSWWkTS5/bbb6ewsJC9996b1atXc8YZZ0RdUlJi1fUBIagfeijqKkQkG40dOzaSFvSOil2LukcPWLUKVq+OuhKR7JKObk6pudr8O8QuqDXyQyT1mjRpwqpVqxTWESufj7pJkyY1el0suz4gBHX//tHWIpIt8vPzKS0tpTYTpklqla/wUhOxDmoRSY2GDRvWaEURiZfYdX3svDPsumuYl1q/pYmIxDCoAcaPh+efh0e1joyISDyD+le/gr594ZxzYAevvBQRyXixDOrcXJg0CUpL4Yoroq5GRCRasQxqgIED4cQT4cYbYdmyqKsREYlObIMaYOJE2LgxLHorIlJfxTqoe/SA006DW2+FJSlf91xEJDPEOqgBfvMbMFNftYjUX7EP6i5d4Mwz4a674IMPoq5GRKTuxT6oAS66CBo1Cn3WIiL1TUYE9a67wtlnwz/+AVWsdykikrUyIqgBxo2D5s3h0kujrkREpG5lTFC3bQvnnQePPAK1XOVLRCQjZUxQQwjqtm3DSBARkfoiqaA2s1Zm9pCZzTezeWZ2YLoLq0zLluHE4rPPwssvR1GBiEjdS7ZFfQMw1d33APoB89JX0vaddRZ07AgTJmgaVBGpH6oNajPbGTgIuAPA3Te6+5fpLqwqTZuGE4qvvgpPPx1VFSIidSeZFnU3YAVwl5m9ZWZ/MbNm2+5kZqPMrMTMStK93M9pp4WVYCZMgC1b0vpRIiKRSyaoc4F9gEnu3h/4Cvj1tju5+23uXuTuRXl5eSku87saNoTf/hZmz4bJk9P6USIikUsmqEuBUnd/PfH4IUJwR2rECOjdO4wA2bgx6mpERNKn2qB290+Bj82sV+KpQ4B301pVEnJy4JprwvwfkyZFXY2ISPokO+rjbOBeM5sDFAKxmCF62DA49NDQDfLFF1FXIyKSHkkFtbvPSvQ/93X3H7t7LGLRDK67LoS0pkEVkWyVUVcmVqZfPzjlFLj55rDGoohItsn4oIYwrnrzZrjqqqgrERFJvawI6oIC+MUv4Pbb4aOPoq5GRCS1siKoAS6+OPRZX3ll1JWIiKRW1gR1ly7wP/8Dd94JH34YdTUiIqmTNUEN4ZLyhg21ZJeIZJesCuoOHWDMGLj3Xnj77airERFJjawKaghLdrVoAZdcEnUlIiKpkXVB3aYNXHghPP44vP569fuLiMRd1gU1wLnnQl5eGAkiIpLpsjKomzcPJxZffBFeeCHqakREdkxWBjXAGWdA586hVa0lu0Qkk2VtUDdpApddBm+8AU8+GXU1IiK1l7VBDXDSSbDbbmEEiJbsEpFMldVB3bAhXH45zJkDDz0UdTUiIrWT1UEN8NOfwt57hxn2ysqirkZEpOayPqhzcsIKMAsWwD/+EXU1IiI1l/VBDXDssdC/f5gDZNOmqKsREamZehHUZmGprkWL4K67oq5GRKRm6kVQQ1gI98AD4Xe/gw0boq5GRCR59Saoy1vVpaVw221RVyMikrx6E9QABx8MQ4bA738PX30VdTUiIsmpV0ENoevjs8/CquUiIpkgqaA2s8Vm9raZzTKzknQXlU6DBoX+6muugTVroq5GRKR6NWlRD3H3QncvSls1deR3v4PPP4frr4+6EhGR6tW7rg+AffcNY6v/+McQ2CIicZZsUDvwTzObYWajKtvBzEaZWYmZlaxYsSJ1FabJ5ZfD2rVw3XVRVyIisn3JBvUP3H0fYBgw2swO2nYHd7/N3YvcvSgvLy+lRaZDnz4wYgTccAMsXx51NSIiVUsqqN19aeLP5cCjwIB0FlVXJk4MF79cfXXUlYiIVK3aoDazZmbWovw+cDjwTroLqwu77w4nnwy33AJLl0ZdjYhI5ZJpUe8CvGJms4E3gKfcfWp6y6o7l14aFhW48sqoKxERqVy1Qe3uC929X+K2t7tnVaQVFMDpp8Ptt4dJm0RE4qZeDs/b1oQJW+etFhGJGwU10KkTnHUW/O1vYYEBEZE4UVAn/PrXYeXyiROjrkRE5LsU1Ant28M558D994fFcEVE4kJBXcEFF0DLlnDZZVFXIiKylYK6gjZt4Pzz4bHHoCSj5wgUkWyioN7GueeGwL7kkqgrEREJFNTbaNkSxo+HqVPhtdeirkZEREFdqdGjoV27sMaiiEjUFNSVaNYMzjsPnnkGZsyIuhoRqe8U1FUYPRpatQoL4YqIRElBXYWWLWHMGHjkEXj77airEZH6TEG9HeecE1rV48ZFXYmI1GcK6u0oH6Y3dWq4iYhEQUFdjdGjoUePcNViWVnU1YhIfaSgrkbjxnDttTB3bphdT0Skrimok3DssbDPPmFtxc2bo65GROobBXUSzODii+H99+Ghh6KuRkTqGwV1ko49FvbYI4yrdo+6GhGpTxTUSWrQAC66KMxV/cQTUVcjIvWJgroGTjgBevUKq8Fs2hR1NSJSXyioa6BhwzACZP78sGq5iEhdUFDX0FFHQXFxWAVm9eqoqxGR+iDpoDazHDN7y8ympLOguDODP/4RVq0KrWsRkXSrSYv6HGBeugrJJPvsAz/9KdxwAyxfHnU1IpLtkgpqM8sHhgN/SW85mePyy2H9erjqqqgrEZFsl2yL+npgHLClqh3MbJSZlZhZyYoVK1JSXJztvjucfDJMmgSlpVFXIyLZrNqgNrMjgeXuvt21Ttz9NncvcveivLy8lBUYZ5deClu2aMkuEUmvZFrUg4CjzWwxcD9wsJndk9aqMkRBAYwaBXfcAQsXRl2NiGSraoPa3S9y93x3LwBGAC+6+4lpryxDTJgAubmhz1pEJB00jnoHdegAv/oV3HMPzNOYGBFJgxoFtbv/y92PTFcxmWr8+LBy+aWXRl2JiGQjtahToF07GDs2TIH61ltRVyMi2UZBnSLnnQetW4c1FkVEUklBnSI77xxWK3/qKfj3v6OuRkSyiYI6hc4+G3bZBS68UIsLiEjqKKhTqFmzcPHLq6/C5MlRVyMi2UJBnWKnngr9+oVukPXro65GRLKBgjrFcnLg+uthyRL405+irkZEsoGCOg2Ki+G//isshPvJJ1FXIyKZTkGdJtdeG9ZVnDAh6kpEJNMpqNOkRw8491y4+26Ysd15B0VEtk9BnUYTJkD79uFiGA3XE5HaUlCnUcuWMHEiTJsWLoQREakNBXWanX56WA1m/HgoK4u6GhHJRArqNGvYMKyr+O67ob9aRKSmFNR14NhjYeBAuPhi+OKLqKsRkUyjoK4DZnDzzbBqVQhrEZGaUFDXkcJCGDMGbr0VXn896mpEJJMoqOvQb38LHTvCmWfqxKKIJE9BXYdatAjzgMyaFbpCRESSoaCuY8cdB0OHwm9+A0uXRl2NiGQCBXUdM4ObbgpdH2PHRl2NiGQCBXUEevQIl5dPngxTp0ZdjYjEnYI6IhdeCL16wejRWmBARLav2qA2syZm9oaZzTazuWZ2eV0Ulu0aN4ZbboGFC8O81SIiVUmmRf0NcLC79wMKgaFmdkB6y6ofDj4Yfv7zcIn59OlRVyMicVVtUHuwLvGwYeKmSTtT5KaboHt3GDECli+PuhoRiaOk+qjNLMfMZgHLgefc/XvX1pnZKDMrMbOSFStWpLrOrNWyJTz4YLi8/OSTNW+1iHxfUkHt7pvdvRDIBwaYWe9K9rnN3YvcvSgvLy/VdWa1wkK47rowAuRvf4u6GhGJmxqN+nD3L4GXgKHpKaf+OussGDQorAajLhARqSiZUR95ZtYqcb8pcBgwP92F1TcNGsDtt8O6dWHyJhGRcsm0qDsAL5nZHOBNQh/1lPSWVT/tuSdceik88ADcf3/U1YhIXJin4exVUVGRl5SUpPx964OyMhg8GObOhTlzoEuXqCsSkbpgZjPcvaiybboyMWZyc+Hvf4ctW+Ckk2Dz5qgrEpGoKahjqHt3+L//g5dfDqNBRKR+U1DH1EknwfHHwyWXwMyZUVcjIlFSUMeUGfz5z9C+PfzsZ/D111FXJCJRUVDHWJs28Ne/woIFcMEFUVcjIlFRUMfcIYfA+efDpEkwRYMiReolBXUGuPJK6NcPTj01rLcoIvWLgjoDNG4cVoNp2hQOOghefDHqikSkLimoM0TPnvDaa9C1KwwbBq+8EnVFIlJXFNQZJD8/jK0uKIBjjw2rw4hI9lNQZ5g2beDJJ8MVi0cdFSZxEpHspqDOQLvvHhYbmDcPxo6NuhoRSTcFdYY69FAYPx7+8hd49NGoqxGRdFJQZ7DLL4d99oHTT1d/tUg2U1BnsEaN4L77wv3DDoNly6KtR0TSQ0Gd4XbfHZ5+Gj77DH70I1i5MuqKRCTVFNRZYP/94bHH4P33w6IDS5dGXZGIpJKCOksceig88wx89BH88IfqsxbJJgrqLFJcDC+8AKtXww9+EJbzEpHMp6DOMgMGhKsX3UM3iJauFMl8Cuos1Lt3mAukRQs4+OAQ3CKSuRTUWapHjxDW+fkwdGgYGSIimUlBncU6dQqt6b32gmOOgQceiLoiEamNaoPazDqb2Utm9q6ZzTWzc+qiMEmNvLwwf/UBB8AJJ8Att0RdkYjUVDIt6jLgfHffCzgAGG1me6W3LEmlnXeGZ5+F4cNh9Gi48ELYsiXqqkQkWdUGtbsvc/eZiftrgXlAp3QXJqm1005h8qZf/hKuuw5GjIANG6KuSkSSkVuTnc2sAOgPvF7JtlHAKIAuXbqkoDRJtdxcuPlm6NYNxo0LVzA+/ji0axd1ZSKyPUmfTDSz5sDDwLnuvmbb7e5+m7sXuXtRXl5eKmuUFDILXR8PPggzZkBREcycGXVVIrI9SQW1mTUkhPS97v5IekuSunD88TB9elgpZtAguO22cJGMiMRPMqM+DLgDmOfu/5v+kqSu7LdfaFX/4Adwxhlw9NFhFj4RiZdkWtSDgJ8DB5vZrMTtiDTXJXWkffswIuT66+G556B/f3j11airEpGKkhn18Yq7m7v3dffCxE3XuWWRBg3gnHPgjTegWbMwudOkSVFXJSLldGWifKtvX3jzzXDJ+VlnwQUXaLy1SBwoqOU7WrUKixD86lfwxz+G1vUrr0RdlUj9pqCW78nJgRtvhNtvh/feCwsRFBfD/ffDxo1RVydS/yiopVJmW1c3/8MfYMmSMFfIPvuEJb9EpO4oqGW7dtop9FV/+CE88gh8+mkY1vf441FXJlJ/KKglKQ0awLHHhhVjuneHH/84zBeybFnUlYlkPwW11EhBAfznP/C734VJnrp0gSOOgMmTNUJEJF0U1FJjjRrBb34TFs89/3x491347/8O/ddPPaVL0UVSTUEttbbbbnD11eGE4z33wNq1cOSRYZTI9OlRVyeSPRTUssMaNICRI2H+/HBF48KFcNBBMGwYvPYalJVFXaFIZlNQS8o0bAhnngkffADXXguvvx5m5mvVKkz49OGHUVcokpkU1JJyO+0U5rxetAjuvRdOOQWmTYN+/cKFNEuWqB9bpCYU1JI2O+8MP/sZ3HQTvP027L9/mPypoADy80Pr+4UXFNoi1VFQS53o3Bmefz7Mf33zzTBwYDgBeeihcNhhYeSIiFTOPA3NmaKiIi8pKUn5+0p2Wb8e7rwzDPVbswYOPzxcpt61K7RtC3vuGeYdEakPzGyGuxdVuk1BLVFbsQJuuAH+/nf46KOtz+flhYtpjjoqhHiLFtHVKJJuCmrJCFu2hL7slSvhk09g6lR45hn44otwkc2YMXDZZdC8edi3gTruJIsoqCVjlZWFpcHuvjvcOnQIQb1wIey7L5x2GgwZEuYfyc2NulqR2tteUKtNIrGWmwuDB8Ndd4XA7t8/DPM791z46qswcqRXrzAk8Igjwqx+69dHXbVIaqlFLRnLHebMgVmzYPbssLDBsmVhLu38fBgwIPRtDxgA3bqF4YIicaWuD6kXyspCv/bMmbBgQbjIprR06/bWrcMY7n33heOOC1dNNm8egl0kagpqqZfcw/wjc+fC4sXhSslFi8IakGvXhn0aNAhh3aIF7L13OFk5cGCkZUs9tb2grvb0i5ndCRwJLHf33qkuTiRdzMJY7D33/O7z33wDzz0XLrJZuzbc1qwJI0wGDQqBvXkzNG4cHu+3H7RrF4YL9uwJbdpE8/eR+qvaFrWZHQSsA/6WbFCrRS2Z6KuvwuXu06dDs2bw5Zdh9r916767X/v2YbHfH/4Qdt01tMY3bQpfABs2hH0OOSRsE0nWDnd9mFkBMEVBLfVNWVnoNvnii7Be5Pvvh5OXL74IS5dW/boGDUKYH3hgaKH37h1a46WlMG9e6G7Jzw8nOTWsUGAHuz5E6rPc3LBAwrbcwwiTVatCt0mjRtCkSbh99VVYCPjRR8PCCps3V/3+zZpBURHssUeYD6VVq9DlUn7bbbcwHFGX0tdvKWtRm9koYBRAly5d9l2yZEmKShTJXN98A++9B++8E1rjnTqFFvb69WG615kzw7zdCxeGKzIr06JFCPLyPvLBg0N3zEMPhS+Kfv1g993DqJbyW9Om4TNatQqfp5Et8aeuD5EMsH59COANG0LAr18fAn7atDBaZcWKcAK0vB+8c+cwgdWcOaFVX5X+/cN8KZ99Bp9/Dh07htf17RuC//PPQ3/87ruHKz+3DfWPPoKHHw5rYv7wh9+/dP/rr0NXUJ8+4X2ldtT1IZIBmjYNt4r69AkzCpb75hsoKQmr6RQVhdB0D2H7xRdbb+vXh/d6/3249Vb47W/DjIRt2oTRLdueIC3Xvn1YRm3QoBD+s2bBE09s7b7p2jX0qzdqFG7u8PLL4f122imsTj9mTO363TdsCF9MOTnhy0W2SmbUx31AMdAO+Ay4zN3v2N5r1KIWiQ/3EIIVvwRWrAghvHBh6FJp0SKMOS8pCa3j8guFOnWCESPg9NPDXOKTJ4cvhU2bYOPG8OeAAfDjH4cvhClTwlDGI44IQf7OO+G9Vq4M/fddu0LLlqGe8lv5aJlVq7Z+IRx+eFhkokWLENy5ueEEbM+e4UuqJjZuDN1L//536PMfPDh8adXUli3ht410dSPpghcRSZp76CZp3Tqc0KzJ66ZMCZfyT50aAq1Pn3A1aLt2IYwXLQqt76ZNt558Lb+1aweFhWGUzVVXheDeVqNGoUW/cWN4n6++2vol1LJl6L7p0SN05SxbFm6ffBL2L2cWun0GDw41l5aGL5Di4lBvfn64SOqpp2D58vAl8d57Ydhmq1bhN4YTTwy/fUAY/fPpp+ELpEmTMPdMbSioRaROlcdKbVufa9eGFnxZWWhlb94cunTmzAm/BTRtGkbMNG8evkzWrw/bFywI21u3Dv3tHTqE3woOOCB053zwAbz0Uri9+moI/o4dw5dDed9/ObMQzJs2hfcYPDi8/8svh+2tW4d9Pv9862t22SWEdm0oqEVEtlFxTvPyvv8FC8LJ065dYfjwra3mimbODCd4FywIX0h9+4ZWeFlZaH0ffXTt6lFQi4jEnOajFhHJYApqEZGYU1CLiMScglpEJOYU1CIiMaegFhGJOQW1iEjMKahFRGIuLRe8mNkKoLYTUrcDqpiZNzZU446Le32gGlNFNSanq7vnVbYhLUG9I8yspKqrc+JCNe64uNcHqjFVVOOOU9eHiEjMKahFRGIujkF9W9QFJEE17ri41weqMVVU4w6KXR+1iIh8Vxxb1CIiUoGCWkQk5mIT1GY21MwWmNkHZvbrqOsBMLPOZvaSmb1rZnPN7JzE823M7Dkzez/xZ+sY1JpjZm+Z2ZTE425m9nrieD5gZo0irq+VmT1kZvPNbJ6ZHRi342hmYxP/zu+Y2X1m1iTq42hmd5rZcjN7p8JzlR43C25M1DrHzPaJsMY/JP6t55jZo2bWqsK2ixI1LjCzH0VRX4Vt55uZm1m7xONIjmF1YhHUZpYD3AwMA/YCTmJWHHsAAAOmSURBVDCzvaKtCoAy4Hx33ws4ABidqOvXwAvu3hN4IfE4aucA8yo8vgb4k7vvBnwB/CKSqra6AZjq7nsA/Qi1xuY4mlknYAxQ5O69gRxgBNEfx7uBods8V9VxGwb0TNxGAZMirPE5oLe79wXeAy4CSPz8jAD2TrzmlsTPf13Xh5l1Bg4HPqrwdFTHcPvcPfIbcCDwbIXHFwEXRV1XJXU+DhwGLAA6JJ7rACyIuK58wg/swcAUwAhXWeVWdnwjqG9nYBGJk9cVno/NcQQ6AR8DbYDcxHH8URyOI1AAvFPdcQNuBU6obL+6rnGbbccC9ybuf+dnG3gWODCK+oCHCI2GxUC7qI/h9m6xaFGz9YekXGniudgwswKgP/A6sIu7L0ts+hTYJaKyyl0PjAO2JB63Bb5097LE46iPZzdgBXBXonvmL2bWjBgdR3dfClxHaF0tA1YDM4jXcSxX1XGL68/RacAzifuxqNHMjgGWuvvsbTbFor5txSWoY83MmgMPA+e6+5qK2zx87UY2xtHMjgSWu/uMqGpIQi6wDzDJ3fsDX7FNN0cMjmNr4BjCl0pHoBmV/LocN1Eft+qY2QRCF+K9UddSzsx2Ai4GLo26lmTFJaiXAp0rPM5PPBc5M2tICOl73f2RxNOfmVmHxPYOwPKo6gMGAUeb2WLgfkL3xw1AKzPLTewT9fEsBUrd/fXE44cIwR2n43gosMjdV7j7JuARwrGN03EsV9Vxi9XPkZmdAhwJjEx8oUA8auxB+EKenfi5yQdmmtmuManve+IS1G8CPRNn2BsRTjY8EXFNmJkBdwDz3P1/K2x6Ajg5cf9kQt91JNz9InfPd/cCwnF70d1HAi8BP0nsFnWNnwIfm1mvxFOHAO8So+NI6PI4wMx2Svy7l9cYm+NYQVXH7QngpMTIhQOA1RW6SOqUmQ0ldMcd7e5fV9j0BDDCzBqbWTfCSbs36rI2d3/b3du7e0Hi56YU2Cfx/zQ2x/A7ou4kr9BpfwTh7PCHwISo60nU9APCr5VzgFmJ2xGEPuAXgPeB54E2UdeaqLcYmJK4353wA/ABMBloHHFthUBJ4lg+BrSO23EELgfmA+8AfwcaR30cgfsIfeabCIHyi6qOG+Ek8s2Jn6G3CSNYoqrxA0Jfb/nPzZ8r7D8hUeMCYFgU9W2zfTFbTyZGcgyru+kSchGRmItL14eIiFRBQS0iEnMKahGRmFNQi4jEnIJaRCTmFNQiIjGnoBYRibn/B7UoU7M+nwCbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3imoT23H1wv5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}