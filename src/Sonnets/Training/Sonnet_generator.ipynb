{
 "cells": [
  {
   "source": [
    "## Can we write a Sonnet like its the middle ages?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![sonnet](Sonnet_art.jpg)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.0 Loading the data\n",
    "<hr/>\n",
    "Let's start with loading the actual data and seeing a small sample of it, say the first 300 characters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "data = open('E:\\CODE\\github-repos\\poetry-generator\\src\\Sonnets\\data\\sonnets.txt').read()\n",
    "data[0:300]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"FROM fairest creatures we desire increase,\\nThat thereby beauty's rose might never die,\\nBut as the riper should by time decease,\\nHis tender heir might bear his memory:\\nBut thou, contracted to thine own bright eyes,\\nFeed'st thy light'st flame with self-substantial fuel,\\nMaking a famine where abundance\""
     },
     "metadata": {},
     "execution_count": 1
    }
   ]
  },
  {
   "source": [
    "### 2.0 Load the packages\n",
    "<hr/>\n",
    "Remeber to check the requirements file for packages used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers \n",
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np "
   ]
  },
  {
   "source": [
    "Checking the tenorflow version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2.1.0\n"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "source": [
    "### 3.0 Tokenizing the traing data\n",
    "<hr/>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total number of words in corpus: 3211\n"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print('Total number of words in corpus:',total_words)"
   ]
  },
  {
   "source": [
    "### 4.0 Preparing the data for training:\n",
    "<hr/>\n",
    "\n",
    "This is the most important part of this entire script and can be broadly split into 5 steps. So let's get into it shall we,\n",
    " #### 4.1) Converting text to sequences.\n",
    " #### 4.2) Creating the N_gram sequences.\n",
    " #### 4.3) Finding the max sequence length and the padding the rest.\n",
    " #### 4.4) Creating the predictors and the labels."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitnlptensorflowcondae601bd9b5aaa464081a20171d131019a",
   "display_name": "Python 3.7.7 64-bit ('nlp_tensorflow': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}